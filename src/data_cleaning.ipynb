{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Code for Data Cleaning \n",
    "**Final Project / Introduction to Econometrics**\n",
    "> Benson Chiu @ NTU IM / B10705047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the list of our needed stations\n",
    "- We collect a list of 104 YouBike stations inside and nearby NTU from https://www.youbike.com.tw/region/main/stations/list/, and put it into `ntu_station_info.txt`.\n",
    "- Read `ntu_station_info.txt` and put the *name of each station* and *capacity of each station* into the dictionary `data`.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ntu_station_info.txt', encoding = \"UTF-8\")\n",
    "text = []\n",
    "\n",
    "for line in f.readlines():\n",
    "    text.append(line[:-1])\n",
    "\n",
    "data = {}\n",
    "for t in range(0, len(text), 3):\n",
    "    name = text[t]\n",
    "    capacity = int(text[t + 1]) + int(text[t + 2])\n",
    "    data[name] = capacity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the dictionary `data` into a dataframe `df`.\n",
    "- Put the name of all stations into the list `name_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(data.items()), columns= [\"Name\", \"Capacity\"])\n",
    "name_list = list(df[\"Name\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset the original dataset\n",
    "- We get the renting and returning records of YouBike 2.0 in Taipei City from 2022/09 to 2022/12 from Taipei City Government (https://data.gov.tw/dataset/150635).\n",
    "- We read the `.csv`  and convert it into a dataframe respectively and then concatenate them into `df_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv files (111-1)\n",
    "df_2022_09 = pd.read_csv('./source_data/2022_09.csv')\n",
    "df_2022_10 = pd.read_csv('./source_data/2022_10.csv')\n",
    "df_2022_11 = pd.read_csv('./source_data/2022_11.csv')\n",
    "df_2022_12 = pd.read_csv('./source_data/2022_12.csv')\n",
    "\n",
    "df_all = pd.concat([df_2022_09, df_2022_10, df_2022_11, df_2022_12], ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We subset the `df_all` by the condition **both rent station and return station must be in our list of 104 stations inside or nearby NTU**.\n",
    "- We also save the resulting dataframe `df_ntu` to a `.csv` file called  `ntu_station_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ntu = df_all[df_all['rent_station'].isin(name_list) & df_all['return_station'].isin(name_list)]\n",
    "df_ntu.to_csv('./final_data/ntu_station_data.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquire all of the locations of the 104 stations.\n",
    "- We get all geographical locations (latitude, longitude) for every station in our list.\n",
    "- We use **Places API** provided by Google Maps\n",
    "  - Documentation: https://developers.google.com/maps/documentation/places/web-service\n",
    "- We use `requests` to fetch the result (in `json` format), we store them into res_json and then put the required elements into the dictionary `locations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the geographical locations of the stations in name_list by Google API\n",
    "import requests\n",
    "locations = {}\n",
    "for name in name_list:\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=YouBike微笑單車 2.0: \"+ name + \"&inputtype=textquery&fields=geometry&key=\"+ api_key\n",
    "    payload= {}\n",
    "    headers = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    res_json = response.json()\n",
    "    locations[name] = [res_json[\"candidates\"][0][\"geometry\"][\"location\"]['lat'], res_json[\"candidates\"][0][\"geometry\"][\"location\"]['lng']]\n",
    "\n",
    "print(locations)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the `for` loop:\n",
    "  - We prepare the dictionary `dict_to_df` which has a more convenient format for `pandas`.\n",
    "  - Also, we prepare the string with all of the location (in url format).\n",
    "- We create a dataframe `df_locations` to store the locations of all 104 stations, also, we export the dataframe to a `.csv` file and we call it `ntu_station_locations.csv`.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_to_df = {\"Name\": [], \"Latitude\":[], \"Longitude\":[]}\n",
    "str_of_locs = \"\"\n",
    "for loc_k, loc_v in locations.items():\n",
    "    dict_to_df[\"Name\"].append(loc_k)\n",
    "    dict_to_df[\"Latitude\"].append(loc_v[0])\n",
    "    str_of_locs += (str(loc_v[0]) + \"%2C\")\n",
    "    dict_to_df[\"Longitude\"].append(loc_v[1])\n",
    "    str_of_locs += (str(loc_v[1]) + \"%7C\")\n",
    "\n",
    "str_of_locs = str_of_locs[:-3]\n",
    "\n",
    "df_locations = pd.DataFrame(dict_to_df)\n",
    "print(df_locations.head())\n",
    "df_locations.to_csv('./final_data/ntu_station_locations.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquire the distance and duration between each pair of station.\n",
    "- We use **Distance Matrix API** provided by Google Maps\n",
    "  - Documentation: https://developers.google.com/maps/documentation/distance-matrix\n",
    "- We create a dataframe `df_distances` to store the distance and duration between each pair of station. Also, we export the dataframe to a `.csv` file and we call it `ntu_station_distances.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the distance matrix\n",
    "import requests\n",
    "res = {\"From\":[], \"To\":[], \"Distance (meters)\":[], \"Duration (seconds)\":[]}\n",
    "list_of_locs = str_of_locs.split('%7C')\n",
    "for o_i, origin in enumerate(list_of_locs):\n",
    "    for d_i, dist in enumerate(list_of_locs):\n",
    "        if origin != dist:\n",
    "            url = \"https://maps.googleapis.com/maps/api/distancematrix/json?origins=\"+ origin +\"&destinations=\"+ dist  +\"&mode=bicycling&region=tw&key=\" + api_key\n",
    "            payload={}\n",
    "            headers = {}\n",
    "            res_2 = requests.request(\"GET\", url, headers=headers, data=payload).json()\n",
    "            distance  = res_2[\"rows\"][0][\"elements\"][0][\"distance\"][\"value\"]\n",
    "            duration  = res_2[\"rows\"][0][\"elements\"][0][\"duration\"][\"value\"]\n",
    "            res[\"From\"].append(name_list[o_i])\n",
    "            res[\"To\"].append(name_list[d_i])\n",
    "            res[\"Distance (meters)\"].append(distance)\n",
    "            res[\"Duration (seconds)\"].append(duration)\n",
    "df_distances = pd.DataFrame(res)\n",
    "df_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distances.to_csv('./final_data/ntu_station_distances.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add capacities to `ntu_station_locations.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = pd.read_csv('./final_data/ntu_station_locations_merged.csv')\n",
    "df_locations = df_locations[[\"Name\", \"Latitude\", \"Longitude\", \"Capacity_x\"]] \n",
    "df_locations.rename(columns= {\"Capacity_x\":\"Capacity\"}, inplace=True)\n",
    "df_locations.to_csv('./final_data/ntu_station_locations.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
